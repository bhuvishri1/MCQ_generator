# MCQ_generator
Automatic_MCQ_generator This project is all about how to generate An Automatic mcq generator ai , how its built and what are the techniques used.We can use Large language models like openAi gpt2 and gpt3 and so on .but here using Bert language model,the question and answers are framed.

BERT is a Language Model for NLP, it is called as Bidirectional encoder representations from Transformers which is pre-trained using texts from wikipedia. Its is based on Transformers, a deep learning model in which every output element is connected to every input element. BERT is pre-trained on two different tasks.Masked Language Modeling and Next Sentence Prediction.

The objective of Masked Language Model (MLM) training is to hide a word in a sentence and then have the program predict what word has been hidden (masked) based on the hidden word's context.

The objective of Next Sentence Prediction training is to have the program predict whether two given sentences have a logical, sequential connection or whether their relationship is simply random.
